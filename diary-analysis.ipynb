{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">H</span><span style=\"color:orange\">E</span><span style=\"color:yellow\">L</span><span style=\"color:green\">L</span><span style=\"color:blue\">O</span> <span style=\"color:violet\">A</span><span style=\"color:blue\">N</span><span style=\"color:green\">D</span> <span style=\"color:yellow\">W</span><span style=\"color:orange\">E</span><span style=\"color:red\">L</span><span style=\"color:orange\">C</span><span style=\"color:yellow\">O</span><span style=\"color:green\">M</span><span style=\"color:blue\">E</span><span style=\"color:violet\">!</span>\n",
    "\n",
    "***What is this notebook about?***\n",
    "\n",
    "This is my attempt to explore my personal diary and the posibilities of knwoledge discovery.\n",
    "\n",
    "***Methodology***\n",
    "\n",
    "I will try to iteratively (monthly) add new perspectives to this search for meaning.\n",
    "\n",
    "***About my diary entries***\n",
    "\n",
    "Unfortunately, I would feel rather uncomfortable to share my dairy entries. But, I will do share all my analysis results! -which is kind of ironic when you think that if I succeed in analysing my data, I will share all my \"secrets\" anyways ðŸ¥´-. \n",
    "\n",
    "Here is some relevant information about the entries:\n",
    "- I write very freely about a range of personal topics, thoughts and feelings.\n",
    "- I write mostly in Spanish, some English, and some of my own language.\n",
    "- I've gathered 21 months of entries so far, totaling over 60 thousand words.\n",
    "\n",
    "### Index\n",
    "1. [Results](#results)\n",
    "2. [Ingestion](#ingestion)\n",
    "3. [References](#references)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='results'></a>\n",
    "## Results\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ingestion'></a>\n",
    "## Data Ingestion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['diary-4.txt', 'diary-5.txt', 'diary-1.txt', 'diary-2.txt', 'diary-3.txt']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sd/c89_7ybj62s9w09y5w6qnvt80000gn/T/ipykernel_25711/1491575498.py:6: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option('display.max_colwidth', -1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "#Read contents of journal archive into list for processing\n",
    "folder='data/'\n",
    "list_of_journals=[]\n",
    "journal_files = os.listdir(folder)\n",
    "print(journal_files)\n",
    "for file in journal_files:\n",
    "    full_file_path=folder+file\n",
    "    list_of_journals.append(full_file_path)\n",
    "    \n",
    "#Create DataFrame shell to load data as we parse through journal\n",
    "journal_df = pd.DataFrame(columns=['year', 'date', 'entry'])\n",
    "\n",
    "#For each file(a single year), read in data.\n",
    "for full_file_path in list_of_journals:\n",
    "    journal_list_of_dicts = []\n",
    "    journal_dict={}\n",
    "    paragraph_list = []\n",
    "    previous_date='NONE'\n",
    "    journal_raw = open(full_file_path)\n",
    "    \n",
    "    #Read in journal line, by line and parse our dates to associate dates with specific entry  \n",
    "    for paragraph in journal_raw.readlines():\n",
    "        #Use pattern matching to parse out date, input can be various formats (May 17, 5/17, 5/17/2020, etc)\n",
    "        pattern = r'(\\d+(\\/|-){1}\\d+(\\/|-)?\\d{0,4})|((Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]*\\s\\d{1,2})'\n",
    "        date_match = re.search(pattern, paragraph, re.IGNORECASE)\n",
    "        if date_match and len(paragraph)<35: #length to prevent mid paragraph dates from being grabbed\n",
    "            if len(journal_list_of_dicts)>0: #this is not the first instance of date, therefore we need to save date and list of paragraphs\n",
    "                journal_dict = {\n",
    "                                'date': previous_date,\n",
    "                                'entry': paragraph_list}\n",
    "                journal_list_of_dicts.append(journal_dict)\n",
    "                #save for use in next loop\n",
    "                previous_date = date_match.group()\n",
    "                #re_initialize list of paragraphs, and journal_dict\n",
    "                paragraph_list = []\n",
    "                journal_dict = {}\n",
    "            else:\n",
    "                if previous_date == 'NONE':\n",
    "                #continue looping and save date, this is the first instance of saving a date - need to continue loop to graph paragraphs\n",
    "                    previous_date = date_match.group()\n",
    "                else:\n",
    "                    #first instance and need to start list of dicts\n",
    "                    journal_dict = {'date': previous_date,\n",
    "                                    'entry': paragraph_list}\n",
    "                    journal_list_of_dicts.append(journal_dict)\n",
    "                    previous_date = date_match.group(0)\n",
    "                    #reset for next date\n",
    "                    paragraph_list = []\n",
    "                    journal_dict = {}\n",
    "        else:\n",
    "            #paragraph is not a date entry is continuing - must be saved to paragraph list\n",
    "            paragraph_list.append(paragraph)\n",
    "    #final entry\n",
    "    journal_dict = {'date': previous_date,\n",
    "                    'entry': paragraph_list}\n",
    "    journal_list_of_dicts.append(journal_dict)\n",
    "    #save to DF and concat to previous\n",
    "    journal_df = pd.concat([pd.DataFrame(journal_list_of_dicts),journal_df], sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='references'></a>\n",
    "## References:\n",
    "Month 1:\n",
    "- I heavily replicated this awesome notebook: https://github.com/datachico/data_mine_journal/blob/Updated_file/NLP_on_a_diary.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
